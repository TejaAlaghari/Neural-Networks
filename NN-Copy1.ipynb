{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = [i for i in range(150)]\n",
    "random.shuffle(r)\n",
    "iris_data = (load_iris()['data'][r], load_iris()['target'][r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(j):\n",
    "    e = np.zeros((3, 1))\n",
    "    e[j] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8 * 150)\n",
    "tr_d = (iris_data[0][:split], iris_data[1][:split])\n",
    "te_d = (iris_data[0][split:], iris_data[1][split:])\n",
    "\n",
    "training_inputs  = [np.reshape(x, (4, 1)) for x in tr_d[0]]\n",
    "training_results = [vectorized_result(y)  for y in tr_d[1]]\n",
    "training_data    = list(zip(training_inputs, training_results))\n",
    "\n",
    "test_inputs = [np.reshape(x, (4, 1)) for x in te_d[0]]\n",
    "test_data   = list(zip(test_inputs, te_d[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 0\n",
    "sizes      = list()\n",
    "biases     = list()\n",
    "weights    = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(sizes_p) :\n",
    "    global num_layers\n",
    "    num_layers = len(sizes_p)\n",
    "    \n",
    "    global sizes\n",
    "    sizes      = sizes_p\n",
    "    \n",
    "    global biases\n",
    "    biases     = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "    \n",
    "    global weights\n",
    "    weights    = [np.random.randn(y, x)/np.sqrt(x) for x, y in list(zip(sizes[:-1], sizes[1:]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "network([4, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward(a) :\n",
    "    global biases\n",
    "    global weights\n",
    "    \n",
    "    for b, w in list(zip(biases, weights)) :\n",
    "        a = sigmoid(np.dot(w, a)+b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(training_data, epochs, mini_batch_size, eta, test_data = None) :\n",
    "    \n",
    "    if test_data :\n",
    "        n_test = len(test_data)\n",
    "    \n",
    "    n = len(training_data)\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        random.shuffle(training_data)\n",
    "        mini_batches = [training_data[k : k + mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "            \n",
    "        for mini_batch in mini_batches:\n",
    "            update_mini_batch(mini_batch, eta)\n",
    "        if test_data:\n",
    "            print(\"Epoch {0}: {1} / {2}\".format(j, evaluate(test_data), n_test))\n",
    "        else:\n",
    "            print(\"Epoch {0} complete\".format(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_mini_batch(mini_batch, eta) :\n",
    "    \n",
    "    global biases\n",
    "    global weights\n",
    "    \n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "    for x, y in mini_batch :\n",
    "        \n",
    "        delta_nabla_b, delta_nabla_w = backprop(x, y)\n",
    "        \n",
    "        nabla_b = [nb + dnb for nb, dnb in list(zip(nabla_b, delta_nabla_b))]\n",
    "        nabla_w = [nw + dnw for nw, dnw in list(zip(nabla_w, delta_nabla_w))]\n",
    "        \n",
    "    weights = [w - (eta / len(mini_batch)) * nw for w, nw in list(zip(weights, nabla_w))]\n",
    "    biases  = [b - (eta / len(mini_batch)) * nb for b, nb in list(zip(biases,  nabla_b))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprop(x, y) :\n",
    "    \n",
    "    global biases\n",
    "    global weights\n",
    "    \n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "        # feedforward\n",
    "    activation = x\n",
    "    activations = [x] \n",
    "    zs = [] \n",
    "    \n",
    "    for b, w in list(zip(biases, weights)) :\n",
    "        z = np.dot(w, activation) + b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        \n",
    "        # backward pass\n",
    "    delta       = cost_derivative(activations[-1], y)\n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "    \n",
    "    for l in range(2, num_layers):\n",
    "        z = zs[-l]\n",
    "        sp = sigmoid_prime(z)\n",
    "        delta = np.dot(weights[-l+1].transpose(), delta) * sp\n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "    \n",
    "    return (nabla_b, nabla_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_data) :\n",
    "    \n",
    "    test_results = [(np.argmax(feedforward(x)), y) for (x, y) in test_data]\n",
    "    \n",
    "    return sum(int(x == y) for (x, y) in test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_derivative(output_activations, y) :\n",
    "    \n",
    "    return (output_activations-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    return (1.0 / (1.0 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(z):\n",
    "    \n",
    "    return (sigmoid(z) * (1 - sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 22 / 30\n",
      "Epoch 1: 22 / 30\n",
      "Epoch 2: 22 / 30\n",
      "Epoch 3: 22 / 30\n",
      "Epoch 4: 22 / 30\n",
      "Epoch 5: 22 / 30\n",
      "Epoch 6: 29 / 30\n"
     ]
    }
   ],
   "source": [
    "SGD(training_data, 7, 15, 0.08, test_data = test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-2.31571157, -1.25988987, -1.27986348, -0.60790617],\n",
       "        [-0.60993532, -0.54248185, -1.67735235, -0.18150551],\n",
       "        [-0.71157045, -0.32667726, -1.30194108,  0.01759045],\n",
       "        [ 0.8721968 ,  3.01925872, -4.02105602, -1.57803457]]),\n",
       " array([[-0.6782173 , -1.10709385, -0.06800146,  7.83825989],\n",
       "        [-0.19956412,  1.21965647,  0.12423629, -4.45720373],\n",
       "        [-0.29210751, -1.07488829,  0.07680355, -4.56525082]])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights #all 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.36518369],\n",
       "        [-1.86651202],\n",
       "        [-1.47424023],\n",
       "        [-1.35289384]]), array([[-4.13176709],\n",
       "        [-0.07749954],\n",
       "        [ 0.04281872]])]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "global weights\n",
    "weights = [np.array([[-2.31571157, -1.25988987, -1.27986348, -0.60790617],\n",
    "        [-0.60993532, -0.54248185, -1.67735235, -0.18150551],\n",
    "        [-0.71157045, -0.32667726, -1.30194108,  0.01759045],\n",
    "        [ 0.8721968 ,  3.01925872, -4.02105602, -1.57803457]]),\n",
    " np.array([[-0.6782173 , -1.10709385, -0.06800146,  7.83825989],\n",
    "        [-0.19956412,  1.21965647,  0.12423629, -4.45720373],\n",
    "        [-0.29210751, -1.07488829,  0.07680355, -4.56525082]])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "global biases\n",
    "biases = [np.array([[-0.36518369],\n",
    "        [-1.86651202],\n",
    "        [-1.47424023],\n",
    "        [-1.35289384]]), np.array([[-4.13176709],\n",
    "        [-0.07749954],\n",
    "        [ 0.04281872]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[-2.31571157, -1.25988987, -1.27986348, -0.60790617],\n",
       "         [-0.60994635, -0.54249142, -1.67735179, -0.18150451],\n",
       "         [-0.71157779, -0.32668262, -1.30194257,  0.01759036],\n",
       "         [ 0.87198157,  3.01974321, -4.02227775, -1.57858206]]),\n",
       "  array([[-0.6782173 , -1.10709033, -0.06799001,  7.87227777],\n",
       "         [-0.19956412,  1.21965563,  0.12423666, -4.47104812],\n",
       "         [-0.29210751, -1.07489057,  0.07679305, -4.58161608]])],\n",
       " [array([[-0.36518369],\n",
       "         [-1.86651449],\n",
       "         [-1.47424177],\n",
       "         [-1.35284137]]), array([[-4.14607664],\n",
       "         [-0.01612644],\n",
       "         [-0.01612065]])])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights, biases #one 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
